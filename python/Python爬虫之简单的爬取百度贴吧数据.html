<html><head><meta charset='utf-8'><meta name='viewport' content='width=device-width, initial-scale=1'>
<meta name='applicable-device' content='pc'><meta name='keywords' content='电脑,电脑讲解,电脑技术,编程,电脑故障维修Python爬虫之简单的爬取百度贴吧数据' />
<script src='../../highlight/highlight.pack.js'></script>
<link rel='stylesheet' type='text/css' href='../../highlight/styles/monokai.css'/>

<link rel='stylesheet' href='../../fenxiang/dist/css/share.min.css'>
<script src='../../fenxiang/src/js/social-share.js'></script>
<script src='../../fenxiang/src/js/qrcode.js'></script>

</head><body><script>hljs.initHighlightingOnLoad();</script><script>
var system ={};  
var p = navigator.platform;       
system.win = p.indexOf('Win') == 0;  
system.mac = p.indexOf('Mac') == 0;  
system.x11 = (p == 'X11') || (p.indexOf('Linux') == 0);     
if(system.win||system.mac||system.xll){
document.write("<link href='../css/3.css' rel='stylesheet' type='text/css'>");}else{ document.write("<link href='../css/3wap.css' rel='stylesheet' type='text/css'>");}</script><script src='../../js/3.js'></script><div class='div2'><div class='heading_nav'><ul><div><li><a href='../../index.html'>首页</a></li>
</div><div onclick='hidden1()' >分享</div>
</ul></div></div>
<div id='heading_nav2'> 
<li class='row' >
<div class='social-share' data-mode='prepend'><a href='javascript:' class='social-share-icon icon-heart'></a></div></li></div><script charset='utf-8' src='../../3/js/hengfu.js'></script><script charset='utf-8' src='../../3/js/hengfu2.js'></script><hr><div class='div1'><div class='biaoti'><center>Python爬虫之简单的爬取百度贴吧数据</center></div><div class='banquan'>原文出处:本文由博客园博主小巩的python笔记提供。<br/>
原文连接:https://www.cnblogs.com/gongdada/p/11620613.html</div><br>
    <h4>首先要使用的第类库有 urllib下的request&nbsp; 以及urllib下的parse&nbsp; 以及 time包&nbsp; random包</h4>
<p>之后我们定义一个名叫BaiduSpider类用来爬取信息</p>
<p>&nbsp;</p>
<p>属性有 url:用来爬取的网址&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;headers:请求头</p>
<div class="cnblogs_code">
<pre><code><span style="color: #0000ff;">class</span><span style="color: #000000;"> BaiduSpider(object):
    </span><span style="color: #0000ff;">def</span> <span style="color: #800080;">__init__</span><span style="color: #000000;">(self):
        self.url </span>= <span style="color: #800000;">'</span><span style="color: #800000;">http://tieba.baidu.com/f?kw={}&amp;pn={}</span><span style="color: #800000;">'</span><span style="color: #000000;">
        self.headers </span>= {<span style="color: #800000;">'</span><span style="color: #800000;">User-Agent</span><span style="color: #800000;">'</span>:<span style="color: #800000;">'</span><span style="color: #800000;">Win7:Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.835.163 Safari/535.1</span><span style="color: #800000;">'</span>}</pre>
</div>
<p>&nbsp;</p>
<h2>之后我们定义三个方法&nbsp; &nbsp;不涉及清洗数据</h2>
<h3>获取页面</h3>
<div class="cnblogs_code">
<pre><code><span style="color: #008080;">1</span> <span style="color: #008000;">#</span><span style="color: #008000;">获取页面</span>
<span style="color: #008080;">2</span>     <span style="color: #0000ff;">def</span><span style="color: #000000;"> get_page(self,url):
</span><span style="color: #008080;">3</span>         <span style="color: #008000;">#</span><span style="color: #008000;">定义请求对象</span>
<span style="color: #008080;">4</span>         req = request.Request(url=url,headers=<span style="color: #000000;">self.headers)
</span><span style="color: #008080;">5</span>         <span style="color: #008000;">#</span><span style="color: #008000;">发起请求</span>
<span style="color: #008080;">6</span>         res =<span style="color: #000000;"> request.urlopen(req)
</span><span style="color: #008080;">7</span>         <span style="color: #008000;">#</span><span style="color: #008000;">获取相应对象</span>
<span style="color: #008080;">8</span>         html = res.read().decode(<span style="color: #800000;">'</span><span style="color: #800000;">utf-8</span><span style="color: #800000;">'</span>, <span style="color: #800000;">'</span><span style="color: #800000;">ignore</span><span style="color: #800000;">'</span><span style="color: #000000;">)
</span><span style="color: #008080;">9</span>         <span style="color: #0000ff;">return</span> html</pre>
</div>
<h3>保存数据</h3>
<div class="cnblogs_code">
<pre><code><span style="color: #008000;">#</span><span style="color: #008000;">保存数据</span>
    <span style="color: #0000ff;">def</span><span style="color: #000000;"> write_page(self,filename,html):
        </span><span style="color: #008000;">#</span><span style="color: #008000;">将数据保存到本地</span>
        with open(filename,<span style="color: #800000;">'</span><span style="color: #800000;">w</span><span style="color: #800000;">'</span>,encoding=<span style="color: #800000;">'</span><span style="color: #800000;">utf-8</span><span style="color: #800000;">'</span><span style="color: #000000;">) as f:
            f.write(html)</span></pre>
</div>
<h3>主函数</h3>
<div class="cnblogs_code">
<pre><code><span style="color: #008000;">#</span><span style="color: #008000;">主函数</span>
    <span style="color: #0000ff;">def</span><span style="color: #000000;"> main(self):
        name </span>= input(<span style="color: #800000;">'</span><span style="color: #800000;">请输入贴吧名:&gt;&gt;&gt;&gt;</span><span style="color: #800000;">'</span><span style="color: #000000;">)
        start </span>= int(input(<span style="color: #800000;">'</span><span style="color: #800000;">请输入起始页</span><span style="color: #800000;">'</span><span style="color: #000000;">))
        end </span>= int(input(<span style="color: #800000;">'</span><span style="color: #800000;">请输入终止页</span><span style="color: #800000;">'</span><span style="color: #000000;">))
        </span><span style="color: #0000ff;">for</span> page <span style="color: #0000ff;">in</span> range(start,end+1<span style="color: #000000;">):
            </span><span style="color: #008000;">#</span><span style="color: #008000;">拼接URL地址 'http://tieba.baidu.com/f?kw{}&amp;pn={}'</span>
            <span style="color: #008000;">#</span><span style="color: #008000;">进行编码 将中文字符编码为url地址编码</span>
            kw =<span style="color: #000000;"> parse.quote(name)
            </span><span style="color: #008000;">#</span><span style="color: #008000;">获取当前页数</span>
            pn = (page-1)*50
            <span style="color: #008000;">#</span><span style="color: #008000;">进行url地址的拼接</span>
            url =<span style="color: #000000;"> self.url.format(kw,pn)
            </span><span style="color: #008000;">#</span><span style="color: #008000;">获取相应</span>
            html =<span style="color: #000000;"> self.get_page(url)
            filename </span>= <span style="color: #800000;">'</span><span style="color: #800000;">{}-第{}页.html</span><span style="color: #800000;">'</span><span style="color: #000000;">.format(name,page)
            self.write_page(filename,html)
            </span><span style="color: #008000;">#</span><span style="color: #008000;">提示</span>
            <span style="color: #0000ff;">print</span>(<span style="color: #800000;">'</span><span style="color: #800000;">第{}页爬取成功</span><span style="color: #800000;">'</span><span style="color: #000000;">.format(page))
            </span><span style="color: #008000;">#</span><span style="color: #008000;">控制爬取速度</span>
            time.sleep(random.randint(1,3))</pre>
</div>
<p>&nbsp;</p>
<h3>最后 所有的代码展示如下</h3>
<div class="cnblogs_code">
<pre><code><span style="color: #008000;">#</span><span style="color: #008000;">导入模块</span>
<span style="color: #0000ff;">from</span> urllib <span style="color: #0000ff;">import</span><span style="color: #000000;"> request,parse
</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> time
</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> random

</span><span style="color: #0000ff;">class</span><span style="color: #000000;"> BaiduSpider(object):
    </span><span style="color: #0000ff;">def</span> <span style="color: #800080;">__init__</span><span style="color: #000000;">(self):
        self.url </span>= <span style="color: #800000;">'</span><span style="color: #800000;">http://tieba.baidu.com/f?kw={}&amp;pn={}</span><span style="color: #800000;">'</span><span style="color: #000000;">
        self.headers </span>= {<span style="color: #800000;">'</span><span style="color: #800000;">User-Agent</span><span style="color: #800000;">'</span>:<span style="color: #800000;">'</span><span style="color: #800000;">Win7:Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.835.163 Safari/535.1</span><span style="color: #800000;">'</span><span style="color: #000000;">}

    </span><span style="color: #008000;">#</span><span style="color: #008000;">获取页面</span>
    <span style="color: #0000ff;">def</span><span style="color: #000000;"> get_page(self,url):
        </span><span style="color: #008000;">#</span><span style="color: #008000;">定义请求对象</span>
        req = request.Request(url=url,headers=<span style="color: #000000;">self.headers)
        </span><span style="color: #008000;">#</span><span style="color: #008000;">发起请求</span>
        res =<span style="color: #000000;"> request.urlopen(req)
        </span><span style="color: #008000;">#</span><span style="color: #008000;">获取相应对象</span>
        html = res.read().decode(<span style="color: #800000;">'</span><span style="color: #800000;">utf-8</span><span style="color: #800000;">'</span>, <span style="color: #800000;">'</span><span style="color: #800000;">ignore</span><span style="color: #800000;">'</span><span style="color: #000000;">)
        </span><span style="color: #0000ff;">return</span><span style="color: #000000;"> html


    </span><span style="color: #008000;">#</span><span style="color: #008000;">解析数据</span>
    <span style="color: #0000ff;">def</span><span style="color: #000000;"> parse_page(self):
        </span><span style="color: #0000ff;">pass</span>

    <span style="color: #008000;">#</span><span style="color: #008000;">保存数据</span>
    <span style="color: #0000ff;">def</span><span style="color: #000000;"> write_page(self,filename,html):
        </span><span style="color: #008000;">#</span><span style="color: #008000;">将数据保存到本地</span>
        with open(filename,<span style="color: #800000;">'</span><span style="color: #800000;">w</span><span style="color: #800000;">'</span>,encoding=<span style="color: #800000;">'</span><span style="color: #800000;">utf-8</span><span style="color: #800000;">'</span><span style="color: #000000;">) as f:
            f.write(html)

    </span><span style="color: #008000;">#</span><span style="color: #008000;">主函数</span>
    <span style="color: #0000ff;">def</span><span style="color: #000000;"> main(self):
        name </span>= input(<span style="color: #800000;">'</span><span style="color: #800000;">请输入贴吧名:&gt;&gt;&gt;&gt;</span><span style="color: #800000;">'</span><span style="color: #000000;">)
        start </span>= int(input(<span style="color: #800000;">'</span><span style="color: #800000;">请输入起始页</span><span style="color: #800000;">'</span><span style="color: #000000;">))
        end </span>= int(input(<span style="color: #800000;">'</span><span style="color: #800000;">请输入终止页</span><span style="color: #800000;">'</span><span style="color: #000000;">))
        </span><span style="color: #0000ff;">for</span> page <span style="color: #0000ff;">in</span> range(start,end+1<span style="color: #000000;">):
            </span><span style="color: #008000;">#</span><span style="color: #008000;">拼接URL地址 'http://tieba.baidu.com/f?kw{}&amp;pn={}'</span>
            <span style="color: #008000;">#</span><span style="color: #008000;">进行编码 将中文字符编码为url地址编码</span>
            kw =<span style="color: #000000;"> parse.quote(name)
            </span><span style="color: #008000;">#</span><span style="color: #008000;">获取当前页数</span>
            pn = (page-1)*50
            <span style="color: #008000;">#</span><span style="color: #008000;">进行url地址的拼接</span>
            url =<span style="color: #000000;"> self.url.format(kw,pn)
            </span><span style="color: #008000;">#</span><span style="color: #008000;">获取相应</span>
            html =<span style="color: #000000;"> self.get_page(url)
            filename </span>= <span style="color: #800000;">'</span><span style="color: #800000;">{}-第{}页.html</span><span style="color: #800000;">'</span><span style="color: #000000;">.format(name,page)
            self.write_page(filename,html)
            </span><span style="color: #008000;">#</span><span style="color: #008000;">提示</span>
            <span style="color: #0000ff;">print</span>(<span style="color: #800000;">'</span><span style="color: #800000;">第{}页爬取成功</span><span style="color: #800000;">'</span><span style="color: #000000;">.format(page))
            </span><span style="color: #008000;">#</span><span style="color: #008000;">控制爬取速度</span>
            time.sleep(random.randint(1,3<span style="color: #000000;">))

</span><span style="color: #0000ff;">if</span> <span style="color: #800080;">__name__</span> == <span style="color: #800000;">'</span><span style="color: #800000;">__main__</span><span style="color: #800000;">'</span><span style="color: #000000;">:
    spider </span>=<span style="color: #000000;"> BaiduSpider()
    spider.main()</span></pre>
</div>
<h3>一个非常非常简单的爬虫就完成了 让我们看一下运行效果截图:</h3>
<p><img src="./images/Python爬虫之简单的爬取百度贴吧数据0.png" alt="" /></p>
<p>&nbsp;</p>
<p>&nbsp;<img src="./images/Python爬虫之简单的爬取百度贴吧数据1.png" alt="" /></p>
<p>&nbsp;</p>
<p>&nbsp;html文件打开后 与我们正常打开的网页并没有太大的差别</p>
<p>&nbsp;</p>
</div>
</div><hr><script charset='utf-8' src='../../js/sming.js'></script></body></html>